#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºå®Œæ•´å¥å­çš„å­—å¹•ä¼˜åŒ–å™¨
æ ¸å¿ƒæ€æƒ³ï¼šæ¯æ¬¡æ˜¾ç¤ºä¸€å¥å®Œæ•´çš„è¯ï¼ˆä¸€å¥è‹±æ–‡+ä¸€å¥ä¸­æ–‡ï¼‰
ä¸å†åˆ‡åˆ†ç ´ç¢çš„å­—å¹•ç‰‡æ®µ
"""

import re
import time
from pathlib import Path
from typing import List, Dict, Tuple
from deep_translator import GoogleTranslator
from utils import setup_logger

logger = setup_logger("sentence_optimizer")

# ä¸“æœ‰åè¯ä¿®æ­£è¡¨
TERM_CORRECTIONS = {
    "Clog code": "Claude Code",
    "clog code": "Claude Code",
    "claude code": "Claude Code",
    "Claude code": "Claude Code",
    "cloud code": "Claude Code",
    "Cloud code": "Claude Code",
    "Cursor": "Cursor IDE",
    "cursor": "Cursor IDE",
    "Windsurf": "Windsurf IDE",
    "MCP": "MCP",
    "Agent OS": "Agent OS",
    "Agent os": "Agent OS",
}

class SubtitleEntry:
    def __init__(self, index: int, start_ms: int, end_ms: int, text: str):
        self.index = index
        self.start_ms = start_ms
        self.end_ms = end_ms
        self.text = text.strip()

    @property
    def duration(self) -> int:
        return self.end_ms - self.start_ms

    def __repr__(self):
        return f"[{self.index}] {self.start_ms}ms-{self.end_ms}ms: {self.text[:50]}..."


def parse_srt_file(srt_path: str) -> List[SubtitleEntry]:
    """è§£æSRTæ–‡ä»¶"""
    with open(srt_path, 'r', encoding='utf-8') as f:
        content = f.read()

    entries = []
    blocks = content.strip().split('\n\n')

    for block in blocks:
        lines = block.strip().split('\n')
        if len(lines) >= 3:
            try:
                index = int(lines[0].strip())

                # è§£ææ—¶é—´æˆ³
                time_line = lines[1].strip()
                start_str, end_str = time_line.split(' --> ')

                start_ms = parse_timestamp_ms(start_str)
                end_ms = parse_timestamp_ms(end_str)

                # æå–æ–‡æœ¬ï¼ˆå¯èƒ½æœ‰ä¸­æ–‡å’Œè‹±æ–‡å¤šè¡Œï¼‰
                text_lines = lines[2:]
                text = ' '.join(line.strip() for line in text_lines)

                entries.append(SubtitleEntry(index, start_ms, end_ms, text))

            except Exception as e:
                logger.warning(f"è·³è¿‡æ— æ•ˆå­—å¹•å—: {e}")
                continue

    return entries


def parse_timestamp_ms(ts: str) -> int:
    """å°† SRT æ—¶é—´æˆ³è½¬æ¢ä¸ºæ¯«ç§’
    ä¾‹å¦‚: 00:00:01,234 -> 1234
    """
    ts = ts.replace(',', '.')
    parts = ts.split(':')
    h = int(parts[0])
    m = int(parts[1])
    s_parts = parts[2].split('.')
    s = int(s_parts[0])
    ms = int(s_parts[1]) if len(s_parts) > 1 else 0
    return h * 3600000 + m * 60000 + s * 1000 + ms


def ms_to_srt_timestamp(ms: int) -> str:
    """å°†æ¯«ç§’è½¬æ¢ä¸º SRT æ—¶é—´æˆ³"""
    h = ms // 3600000
    ms %= 3600000
    m = ms // 60000
    ms %= 60000
    s = ms // 1000
    ms %= 1000
    return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"


def is_sentence_end(text: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯å¥å­ç»“å°¾"""
    text = text.strip()
    end_markers = ('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ', '...', 'â€¦')
    return any(text.endswith(marker) for marker in end_markers)


def merge_subtitles_by_sentence(entries: List[SubtitleEntry]) -> List[Tuple[int, int, str]]:
    """å°†ç ´ç¢çš„å­—å¹•åˆå¹¶ä¸ºå®Œæ•´å¥å­

    è¿”å›: [(start_ms, end_ms, merged_text), ...]
    """
    if not entries:
        return []

    merged = []
    current_group = [entries[0]]
    current_text = entries[0].text

    for i in range(1, len(entries)):
        entry = entries[i]

        # å¦‚æœå½“å‰æ–‡æœ¬å·²ç»ä»¥å¥å·ç»“å°¾ï¼Œæˆ–è€…æ˜¯æ–°çš„å¥å­å¼€å§‹
        if is_sentence_end(current_text) or current_text.endswith('"'):
            # ä¿å­˜å½“å‰ç»„
            start_ms = current_group[0].start_ms
            end_ms = current_group[-1].end_ms
            merged_text = ' '.join(e.text for e in current_group)
            merged.append((start_ms, end_ms, merged_text))

            # å¼€å§‹æ–°ç»„
            current_group = [entry]
            current_text = entry.text
        else:
            # ç»§ç»­ç´¯ç§¯
            current_group.append(entry)
            current_text += ' ' + entry.text

            # é˜²æ­¢å¥å­è¿‡é•¿ï¼ˆæœ€å¤šåˆå¹¶5æ¡åŸå§‹å­—å¹•ï¼‰
            if len(current_group) >= 5:
                start_ms = current_group[0].start_ms
                end_ms = current_group[-1].end_ms
                merged_text = ' '.join(e.text for e in current_group)
                merged.append((start_ms, end_ms, merged_text))
                current_group = []
                current_text = ""

    # ä¿å­˜æœ€åä¸€ç»„
    if current_group:
        start_ms = current_group[0].start_ms
        end_ms = current_group[-1].end_ms
        merged_text = ' '.join(e.text for e in current_group)
        merged.append((start_ms, end_ms, merged_text))

    logger.info(f"åˆå¹¶å­—å¹•: {len(entries)} æ¡åŸå§‹ -> {len(merged)} æ¡å®Œæ•´å¥å­")
    return merged


def split_long_sentence_by_duration(start_ms: int, end_ms: int, text: str) -> List[Tuple[int, int, str]]:
    """æ ¹æ®æ—¶é•¿æ™ºèƒ½åˆ‡åˆ†é•¿å¥å­

    ç­–ç•¥ï¼š
    - < 5ç§’ï¼šä¿æŒå®Œæ•´
    - 5-10ç§’ï¼šåœ¨ä¸»è¦æ ‡ç‚¹å¤„åˆ‡åˆ†ï¼ˆã€‚ï¼ï¼Ÿ.!?ï¼‰
    - > 10ç§’ï¼šåœ¨æ¬¡è¦æ ‡ç‚¹å¤„ä¹Ÿåˆ‡åˆ†ï¼ˆï¼Œï¼›,:ï¼›:ï¼‰

    è¿”å›: [(start_ms, end_ms, text_segment), ...]
    """
    duration_sec = (end_ms - start_ms) / 1000

    # çŸ­å¥å­ï¼šä¿æŒå®Œæ•´
    if duration_sec < 5:
        return [(start_ms, end_ms, text)]

    # å¯»æ‰¾åˆ‡åˆ†ç‚¹
    segments = []
    if duration_sec < 10:
        # ä¸­ç­‰é•¿åº¦ï¼šåœ¨ä¸»è¦æ ‡ç‚¹å¤„åˆ‡åˆ†
        split_chars = ('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ')
    else:
        # é•¿å¥å­ï¼šåœ¨é€—å·å¤„ä¹Ÿåˆ‡åˆ†
        split_chars = ('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ', ',', 'ï¼Œ', ';', 'ï¼›', ':', 'ï¼š')

    # æŒ‰åˆ‡åˆ†ç‚¹åˆ†å‰²
    parts = []
    current_part = ""

    for char in text:
        current_part += char
        if char in split_chars:
            parts.append(current_part.strip())
            current_part = ""

    if current_part.strip():
        parts.append(current_part.strip())

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ‡åˆ†ç‚¹ï¼Œä¿æŒå®Œæ•´
    if len(parts) <= 1:
        return [(start_ms, end_ms, text)]

    # æ ¹æ®æ—¶é—´åˆ†é…æ—¶é•¿
    total_chars = sum(len(p) for p in parts)
    current_time = start_ms

    for i, part in enumerate(parts):
        if i == len(parts) - 1:
            # æœ€åä¸€ä¸ªéƒ¨åˆ†ä½¿ç”¨å‰©ä½™æ—¶é—´
            part_end = end_ms
        else:
            # æŒ‰å­—ç¬¦æ¯”ä¾‹åˆ†é…æ—¶é—´
            part_duration = int((end_ms - start_ms) * (len(part) / total_chars))
            part_end = current_time + part_duration
            # ç¡®ä¿è‡³å°‘æœ‰1ç§’çš„æ˜¾ç¤ºæ—¶é—´
            if part_end - current_time < 1000:
                part_end = current_time + 1000

        segments.append((current_time, part_end, part))
        current_time = part_end

    # ä¿®æ­£æœ€åä¸€ä¸ªéƒ¨åˆ†çš„æ—¶é—´
    if segments:
        segments[-1] = (segments[-1][0], end_ms, segments[-1][2])

    logger.debug(f"åˆ‡åˆ†é•¿å¥å­ ({duration_sec:.1f}ç§’): {len(segments)} æ®µ")
    return segments


def correct_terms(text: str) -> str:
    """ä¿®æ­£ä¸“æœ‰åè¯"""
    for wrong, correct in TERM_CORRECTIONS.items():
        text = re.sub(r'\b' + re.escape(wrong) + r'\b', correct, text, flags=re.IGNORECASE)
    return text


def translate_sentences(sentences: List[Tuple[int, int, str]],
                        source_lang: str = 'en',
                        target_lang: str = 'zh-CN') -> List[Dict]:
    """ç¿»è¯‘å¥å­åˆ—è¡¨ï¼ˆåŒ…å«æ™ºèƒ½åˆ‡åˆ†ï¼‰

    è¿”å›: [{'start': ms, 'end': ms, 'english': str, 'chinese': str}, ...]
    """
    translator = GoogleTranslator(source=source_lang, target=target_lang)

    results = []

    for i, (start_ms, end_ms, english) in enumerate(sentences):
        try:
            # ä¿®æ­£ä¸“æœ‰åè¯
            english = correct_terms(english)

            # æ™ºèƒ½åˆ‡åˆ†é•¿å¥å­
            split_sentences = split_long_sentence_by_duration(start_ms, end_ms, english)

            for seg_start, seg_end, seg_english in split_sentences:
                # ç¿»è¯‘
                chinese = translator.translate(seg_english)

                # æ¸…ç†ç¿»è¯‘ç»“æœ
                chinese = chinese.strip()

                results.append({
                    'start': seg_start,
                    'end': seg_end,
                    'english': seg_english,
                    'chinese': chinese
                })

                logger.info(f"[{len(results)}] {seg_english[:60]}... -> {chinese[:60]}...")

            # é€Ÿç‡é™åˆ¶
            time.sleep(0.2)

        except Exception as e:
            logger.error(f"ç¿»è¯‘å¤±è´¥: {e}")
            # å¤±è´¥æ—¶ä¿ç•™è‹±æ–‡
            results.append({
                'start': start_ms,
                'end': end_ms,
                'english': english,
                'chinese': "[ç¿»è¯‘å¤±è´¥]"
            })

    return results


def fix_overlaps_gentle(subtitles: List[Dict], min_gap_ms: int = 200):
    """æ¸©å’Œåœ°ä¿®å¤é‡å  - åªç¼©çŸ­è¿‡é•¿çš„å­—å¹•ï¼Œä¿æŒè¶³å¤Ÿæ—¶é•¿

    ç­–ç•¥ï¼š
    1. å¦‚æœä¸¤æ¡å­—å¹•é‡å ï¼Œç¼©çŸ­å‰ä¸€æ¡
    2. ç¡®ä¿æ¯æ¡å­—å¹•è‡³å°‘æœ‰ 1 ç§’çš„æ˜¾ç¤ºæ—¶é—´
    3. å¦‚æœæ— æ³•ç¼©çŸ­ï¼ˆæ—¶é•¿ä¸è¶³ï¼‰ï¼Œåˆ™è®©ä¸‹ä¸€æ¡å»¶è¿Ÿå¼€å§‹
    """
    if len(subtitles) <= 1:
        return

    for i in range(len(subtitles) - 1):
        current = subtitles[i]
        next_sub = subtitles[i + 1]

        current_end = current['end']
        next_start = next_sub['start']

        # æ£€æµ‹é‡å 
        if current_end > next_start - min_gap_ms:
            # å°è¯•ç¼©çŸ­å½“å‰å­—å¹•
            min_duration = 1000  # æœ€å°‘ 1 ç§’
            ideal_end = next_start - min_gap_ms

            if ideal_end >= current['start'] + min_duration:
                # å¯ä»¥ç¼©çŸ­
                current['end'] = ideal_end
                logger.debug(f"ç¼©çŸ­å­—å¹• {i+1}: {current_end}ms -> {ideal_end}ms")
            else:
                # ä¸èƒ½ç¼©çŸ­ï¼Œå»¶è¿Ÿä¸‹ä¸€æ¡
                next_sub['start'] = current_end + min_gap_ms
                logger.debug(f"å»¶è¿Ÿå­—å¹• {i+2}: {next_start}ms -> {next_sub['start']}ms")


def save_bilingual_srt(subtitles: List[Dict], output_path: str):
    """ä¿å­˜åŒè¯­ SRT æ–‡ä»¶

    æ ¼å¼ï¼š
    1
    00:00:00,240 --> 00:00:04,560
    English text here
    ä¸­æ–‡ç¿»è¯‘åœ¨è¿™é‡Œ
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        for i, sub in enumerate(subtitles, 1):
            start_ts = ms_to_srt_timestamp(sub['start'])
            end_ts = ms_to_srt_timestamp(sub['end'])

            f.write(f"{i}\n")
            f.write(f"{start_ts} --> {end_ts}\n")
            f.write(f"{sub['english']}\n")
            f.write(f"{sub['chinese']}\n")
            f.write("\n")

    logger.info(f"âœ… å­—å¹•å·²ä¿å­˜: {output_path}")
    logger.info(f"   æ€»è®¡ {len(subtitles)} æ¡å­—å¹•")


def optimize_srt(input_srt: str, output_srt: str) -> bool:
    """ä¸»å‡½æ•°ï¼šä¼˜åŒ– SRT å­—å¹•

    Args:
        input_srt: è¾“å…¥çš„åŸå§‹ SRT æ–‡ä»¶è·¯å¾„
        output_srt: è¾“å‡ºçš„ä¼˜åŒ–å SRT æ–‡ä»¶è·¯å¾„

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    logger.info(f"ğŸš€ å¼€å§‹ä¼˜åŒ–å­—å¹•: {input_srt}")

    # 1. è§£æåŸå§‹å­—å¹•
    entries = parse_srt_file(input_srt)
    logger.info(f"ğŸ“– è¯»å–åˆ° {len(entries)} æ¡åŸå§‹å­—å¹•")

    if not entries:
        logger.error("âŒ æ²¡æœ‰è¯»å–åˆ°å­—å¹•")
        return False

    # 2. åˆå¹¶ä¸ºå®Œæ•´å¥å­
    sentences = merge_subtitles_by_sentence(entries)

    # 3. ç¿»è¯‘
    translated = translate_sentences(sentences)

    # 4. ä¿®å¤é‡å 
    fix_overlaps_gentle(translated, min_gap_ms=200)

    # 5. ä¿å­˜
    save_bilingual_srt(translated, output_srt)

    # æ‰“å°é¢„è§ˆ
    logger.info("\nğŸ” é¢„è§ˆå‰ 3 æ¡å­—å¹•:")
    for i, sub in enumerate(translated[:3], 1):
        logger.info(f"\n[{i}] {ms_to_srt_timestamp(sub['start'])} --> {ms_to_srt_timestamp(sub['end'])}")
        logger.info(f"  EN: {sub['english']}")
        logger.info(f"  ZH: {sub['chinese']}")

    return True


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 3:
        print("ç”¨æ³•: python sentence_subtitle_optimizer.py <input.srt> <output.srt>")
        print("\nç¤ºä¾‹:")
        print('  python sentence_subtitle_optimizer.py "subs_raw/video.en.srt" "subs_translated/video_optimized.srt"')
        sys.exit(1)

    input_file = sys.argv[1]
    output_file = sys.argv[2]

    if not Path(input_file).exists():
        logger.error(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        sys.exit(1)

    try:
        success = optimize_srt(input_file, output_file)
        if success:
            logger.info("\nâœ… ä¼˜åŒ–å®Œæˆ!")
        else:
            logger.error("\nâŒ ä¼˜åŒ–å¤±è´¥")
            sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        sys.exit(1)
